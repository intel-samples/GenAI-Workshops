{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1c052f-2263-4b74-986d-66ab48ff4a24",
   "metadata": {},
   "source": [
    "<img src=\"https://opea.dev/wp-content/uploads/sites/9/2024/04/opea-horizontal-color.svg\" alt=\"OPEA Logo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca985481",
   "metadata": {},
   "source": [
    "# Deploy and Learn ChatQnA using OPEA on Intel Tiber AI Cloud \n",
    "## Replace your LLM model from your deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891b72b",
   "metadata": {},
   "source": [
    "# üì¶ What Is a Helm Chart?\n",
    "\n",
    "A **Helm chart** is a collection of YAML templates that describe Kubernetes resources. Helm makes it easy to package, configure, and deploy applications to Kubernetes clusters. It is the de facto standard for Kubernetes application deployment.\n",
    "\n",
    "Helm allows developers to:\n",
    "- Define application components using templates\n",
    "- Configure deployments using values files (`values.yaml`)\n",
    "- Deploy applications with a single command\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665ad60",
   "metadata": {},
   "source": [
    "## üì¶ Helm Chart Structure (OPEA GenAIInfra)\n",
    "\n",
    "This Helm chart is part of the [GenAIInfra](https://github.com/opea-project/GenAIInfra) repository, which provides infrastructure templates to deploy multiple OPEA blueprints on Kubernetes.\n",
    "\n",
    "For this example, we will be exploring ChatqnA blueprint. The `chatqna` chart defines the resources required to deploy an end-to-end RAG-based question-answering application using modular microservices (LLM backend, retriever service, data prep, etc.).\n",
    "\n",
    "```text\n",
    "helm-charts/\n",
    "‚îî‚îÄ‚îÄ chatqna/\n",
    "    ‚îú‚îÄ‚îÄ Chart.yaml         # Chart metadata (e.g., name, version, description)\n",
    "    ‚îú‚îÄ‚îÄ values.yaml        # Default configuration values for the chart\n",
    "    ‚îú‚îÄ‚îÄ templates/         # Kubernetes resource templates\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml    # Defines Pods, containers, and other resources for LLM, retriever, etc.\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml       # Defines the networking setup and service exposure\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ configmap.yaml     # Configuration settings injected as environment variables\n",
    "    ‚îî‚îÄ‚îÄ charts/            # Subcharts (if used, for nested Helm charts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9f7c2",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è How to Customize a Helm Chart. \n",
    "## Custom Configuration: `cpu-values.yaml`\n",
    "\n",
    "The `cpu-values.yaml` file is **not part of the Helm chart directory** itself ([`helm-charts/chatqna`](https://github.com/opea-project/GenAIInfra/tree/main/helm-charts/chatqna)), because it is meant to be a **user-provided override configuration**.\n",
    "\n",
    "### Why isn‚Äôt `cpu-values.yaml` inside the chart?\n",
    "\n",
    "Helm encourages a clean separation between:\n",
    "- `values.yaml`: the default configuration that comes with the chart (e.g. default model, retriever backend, etc.).\n",
    "- Custom override files: like `cpu-values.yaml`, these allow you to tailor deployments for specific environments (such as CPU-only machines or resource-constrained nodes) without editing the upstream chart.\n",
    "\n",
    "### Benefits of using `cpu-values.yaml`\n",
    "\n",
    "- Keeps the chart generic and reusable.\n",
    "- Allows multiple profiles like:\n",
    "  - `cpu-values.yaml` ‚Äì for CPU-based deployments.\n",
    "  - `gpu-values.yaml` ‚Äì for GPU-enabled clusters.\n",
    "  - `dev-values.yaml` ‚Äì for development/test clusters.\n",
    "- Makes upgrades and version tracking easier since your overrides are managed separately.\n",
    "\n",
    "To deploy using `cpu-values.yaml` and to change `chatqna` application with a custom Hugging Face model (e.g., `deepseek-ai/DeepSeek-R1-Distill-Qwen-7B`), run the following command:\n",
    "\n",
    "```bash\n",
    "helm upgrade --install chatqna oci://ghcr.io/opea-project/charts/chatqna \\\n",
    "  --set vllm.LLM_MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \\\n",
    "  -f cpu-values.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm upgrade --install chatqna oci://ghcr.io/opea-project/charts/chatqna \\\n",
    "  --set vllm.LLM_MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \\\n",
    "  -f cpu-values.yaml && kubectl logs -l app=chatqna --tail=50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
